# Invoice processing

## Library documentation

- [transformer: layoutLM](https://huggingface.co/transformers/model_doc/layoutlm.html)

## State of the art documentation

- [Gradient-Based Learning Applied to document Recognition](https://github.com/jhubar/invoiceProcessing/blob/master/Documentation/lecun-98.pdf)
- [ResNetImplementation](https://github.com/akshaymehra24/WideResnet)
- [Fine-Tuning Transformer Model for Invoice Recognition](https://www.kdnuggets.com/2021/06/fine-tuning-transformer-model-invoice-recognition.html)
- [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/pdf/1912.13318.pdf)

# How do you measure the performance the goodnest of our prediciton

A standard performance indicator for object detection is to evaluate the intersection over union (IoU) between a predicted bounding box $\hat{B}$ and an annotated bounding box $B$, 

![equation](\text{IoU}(B,\hat{B}) = \frac{\text{area}(B \cap \hat{B})}{\text{area}(B \cup \hat{B})})


